---
title: "Tidyr Soil"
author: "Apryl Perry, Clarice Perryman, Jochen Wirsing""
title: "Tidyr Soil"
author: "Apryl Perry"
date: "February 28, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Clear workspace (if desired/needed)
```{r}
rm(list = ls())
```

Check and/or change working directory
```{r}
#getwd()
#setwd("~/NR995")
```

Load libraries
```{r}
library(tidyverse)
library(dplyr)

```

Read in data file, ignored first 4 rows - blank and or random file info, blank cells to NA
```{r}
B_Soil <- read.csv("C:/Users/Apryl/Documents/NR995/BestValue_Soil.csv", header = TRUE, skip = 4, na.strings = c(NA, ""))
```

Figure out which columns to remove/drop or expand 
Removed all columns ending with Sum, these are repeat info of existing columns. Create new df with only desired chemical species.  Add desired columns to chem database
```{r}
NoSum <- select (B_Soil, -c(ends_with('_Sum')))



Our_Chem <- select(NoSum, starts_with("Hg_"), starts_with("Pb_"), starts_with("Ni_"), starts_with('As') , starts_with('Cd'), starts_with('Pb'), starts_with('Ti'))

data1 <- select(NoSum, matches('LAB_ID|FIELD_ID|DATE_SUBMITTED|DATE_COLLECT|LATITUDE|LONGITUDE|QUAD|SPHEROID|DATUM|DEPTH|SAMPLE_SOURCE|LOCATE_DESC|PRIMARY_CLASS|SAMPLE_COMMENT|SAMPLE_ZONE|HORIZON|ORGANICS|DRAINAGE|PREP|Hg_|Pb_|Ni_|As_|Cd_|Cr_|Tl_'))


```


Filtering everything that has no info on one of the following:

* depth
* sample source

```{r latlon_depth}

data2 <- filter(data1, is.na(DEPTH) == FALSE | is.na(SAMPLE_SOURCE) == FALSE)


```


Loading the whole US geochem file -- national geochemical survey data base

And filtering for just alaska (by latitude > 52 deg north) and for just soil data

```{r load_us_geochem}

usgeochem <- read.csv("geochem.csv", header = T, na.strings = "")

AKgeochem <- filter(usgeochem, LATITUDE > 52.000 & TYPEDESC == "SOIL")


```


Filtering for chemistry (As, Cd, Pb, Hg, Ni, Cr, Tl)


```{r chemfilter}


# Cleaner code - also fixing typo in varname
AKgeochem_2 <- select(AKgeochem,REC_NO,LABNO,LABNO2,FLDNAM,COLL_DATE,FLDNAM_AN,DESCRIPT,SOIL_HORIZ,SETTING,DATUM,LATITUDE,LONGITUDE,CONTAMSOU,CONTAMPOT,CONTAMDEGR,VEG,ANAL_NOTES,QUAD24CODE,FIPS,CATEGORY,TYPEDESC, matches('HG_|PB_|NI_|AS_|CD_|CR_|TL_'))

# we lose the variables PREV_LABNO & VEG_DENS, but I don't think they are wanted anyway


# Getting rid of NURE variables

AKgeochem_2 <- select(AKgeochem_2, -c(AS_NURE, CD_NURE, HG_NURE, NI_NURE, PB_NURE))


```



```{r longform1}

AKgeochem_2_long <- gather(AKgeochem_2, key = Feature, value = value, -REC_NO)

#this results in some variables being dropped which can be fixed by converting them into characters and then - after turning everything in long form - switching them back into factors with levels. This is why I tagged the uploaded file "Caution"

```


## PLUTOsoil

```{r reading_pluto}

library(foreign)

pluto <- read.dbf("plutosoil.dbf")

pluto <- pluto %>% filter(STATE == "AK")


pluto_2 <- select(pluto,id,LABNO,FIELD,JOBN,STATE, COUNTY,LATITUDE,LONGITUDE,MAT,DESCRIPTN_,NAME,SUB__DATE,B12, B13, B20, B21, B22, TOA, matches('HG_|Q_HG|PB_|Q_PB|NI_|Q_NI|AS_|Q_AS|CD_|Q_CD|CR_|Q_CR|TL_|Q_TL'))

pluto_2 <- rename(pluto_2, SUB_DATE = SUB__DATE)
pluto_2 <- rename(pluto_2, DESCRIPT = DESCRIPTN_)

```

